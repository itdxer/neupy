<!DOCTYPE html><!--[if lt IE 7]>      <html xmlns="http://www.w3.org/1999/xhtml"
    xmlns:og="http://ogp.me/ns#"
    xmlns:fb="https://www.facebook.com/2008/fbml" class="no-js lt-ie9 lt-ie8 lt-ie7"> <![endif]-->
<!--[if IE 7]>         <html xmlns="http://www.w3.org/1999/xhtml"
    xmlns:og="http://ogp.me/ns#"
    xmlns:fb="https://www.facebook.com/2008/fbml" class="no-js lt-ie9 lt-ie8"> <![endif]-->
<!--[if IE 8]>         <html xmlns="http://www.w3.org/1999/xhtml"
    xmlns:og="http://ogp.me/ns#"
    xmlns:fb="https://www.facebook.com/2008/fbml" class="no-js lt-ie9"> <![endif]-->
<!--[if gt IE 8]><!--> <html xmlns="http://www.w3.org/1999/xhtml"
    xmlns:og="http://ogp.me/ns#"
    xmlns:fb="https://www.facebook.com/2008/fbml" class="no-js"> <!--<![endif]-->
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
        <meta name="description" content="NeuPy is a Python library for Artificial Neural Networks. NeuPy supports many different types of Neural Networks from a simple perceptron to deep learning models.">
        <meta name="viewport" content="width=device-width">
        <title>Transfer Learning &mdash; NeuPy</title>
            <link rel="stylesheet" href="../_static/normalize.css" type="text/css">
            <link rel="stylesheet" href="../_static/sphinx.css" type="text/css">
            <link rel="stylesheet" href="../_static/main.css" type="text/css">
            <link rel="stylesheet" href="../_static/flat.css" type="text/css">
            <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
            <link rel="stylesheet" href="../_static/font-awesome.min.css" type="text/css">
        <link rel="shortcut icon" href="../_static/favicon.ico" /><!-- Load modernizr and JQuery -->
        <script src="../_static/vendor/modernizr-2.6.2.min.js"></script>
        <script src="//ajax.googleapis.com/ajax/libs/jquery/1.8.2/jquery.min.js"></script>
        <script>window.jQuery || document.write('<script src="../_static/vendor/jquery-1.8.2.min.js"><\/script>')</script>
        <script src="../_static/plugins.js"></script>
        <script src="../_static/main.js"></script>
        <link rel="search" title="Search" href="../search.html" /><link rel="next" title="Storage for Neural Networks" href="storage.html" /><link rel="prev" title="Scikit-learn compatibility" href="algorithms/sklearn-compatibility.html" /><link rel="alternate" type="application/rss+xml" title="RSS" href="../rss.html" /><script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../',
        VERSION:     '1.7.1',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        SOURCELINK_SUFFIX: '.txt',
        HAS_SOURCE:  true
      };
    </script><script type="text/javascript" src="../_static/underscore.js"></script><script type="text/javascript" src="../_static/doctools.js"></script><script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script type="text/javascript" src="../_static/disqus.js"></script><script type="text/javascript" src="../_static/js/google_analytics.js"></script><script type="text/javascript" src="../_static/js/script.js"></script><script type="text/javascript" src="../_static/js/copybutton.js"></script>

    <script type="text/javascript">
        $(document).ready(function () {
            // Scroll to content if on small screen
            if (screen.width < 480)
            {
                $(document).scrollTop(document.getElementsByTagName("article")[0].offsetTop - 44);
            }
        });
    </script>
    <style media="screen" type="text/css">
        img { max-width: 800px !important; }
        img[src="../_images/mnist-code-sample-home.png"] { max-width: 600px !important; }
        table { background-color: white; }
        div.highlight { margin-bottom: 20px !important; }

        .limited-width { max-width: 800px; margin: auto; }
        .docutils { width: 100%; }
        .docutils td { padding: 10px; }
        .section { word-wrap:break-word; }
        .descname { font-weight: bold; }
        .highlight-python + .figure { margin-top: 20px; }
        .dataframe { text-align: center !important; width: 100%; margin: 10px 0 10px 0; }
        .dataframe td { padding: 5px; }

        .math .gd { color: #000 !important; } /* Generic.Deleted */
        .math .m { color: #000 !important; } /* Literal.Number */
        .math .s { color: #000 !important; } /* Literal.String */
        .math .mf { color: #000 !important; } /* Literal.Number.Float */
        .math .mh { color: #000 !important; } /* Literal.Number.Hex */
        .math .mi { color: #000 !important; } /* Literal.Number.Integer */
        .math .mo { color: #000 !important; } /* Literal.Number.Oct */
        .math .sc { color: #000 !important; } /* Literal.String.Char */
        .math .s2 { color: #000 !important; } /* Literal.String.Double */
        .math .si { color: #000 !important; } /* Literal.String.Interpol */
        .math .sx { color: #000 !important; } /* Literal.String.Other */
        .math .s1 { color: #000 !important; } /* Literal.String.Single */
        .math .ss { color: #000 !important; } /* Literal.String.Symbol */
        .math .il { color: #000 !important; } /* Literal.Number.Integer.Long */

        /* Background for class and function names */
        dt[id^="neupy."] {
            background-color: #e6edf2;
            border: 1px solid #f8fafb;
            border-radius: 8px;
            padding: 10px 20px;
        }
        div[id^="module-neupy."] h1 {
            display: none;
        }

        /* Search input field */
        .search-input {
            width: 100%;
            padding: 10px;
            display: block;
        }
        .box {
          padding-bottom: 50px;
        }
        .search-input-container {
          width: 100%;
          vertical-align: middle;
          white-space: nowrap;
          position: relative;
        }
        .search-input-container input#search {
          width: 100%;
          height: 50px;
          padding-left: 45px;

          float: left;
          outline: none;
          border: 1px solid #ddd;

          box-sizing: border-box;
          -webkit-box-sizing: border-box;
          -moz-box-sizing: border-box;

          -webkit-border-radius: 5px;
          -moz-border-radius: 5px;
          border-radius: 5px;

          font-family: 'PT Sans', Helvetica, Arial, sans-serif;
          font-size: 12pt;
        }
        .search-input-container .icon {
          position: absolute;
          left: 0;
          top: 50%;
          margin-left: 17px;
          margin-top: 13px;
          z-index: 1;
          color: #93a4ad;
        }

        .docutils.field-list, .docutils.footnote {
            background-color: inherit;
        }
        .large-font {
            font-size: 1.4em !important;
        }
        .right-tag {
            float: right;
            margin-left: 36px !important;
            margin-right: 0px !important;
        }
        .short-description {
            /* We hidde description inside of the article */
            display: none;
        }
        .short-description img {
            max-height: 160px;
            max-width: 40% !important;
            margin-left: 8px;
        }
        #results-list ul.search {
            padding: 0;
            max-width: 900px;
            margin: auto;
        }

        #results-list .short-description {
            /* We show description text in the archive */
            display: block !important;
        }
        #results-list li p {
            margin-bottom: 5px;
            font-size: 0.9em;
        }
        #results-list li {
            background-color: #fff !important;
            margin-bottom: 10px;
            display: block !important;
            padding: 15px;
            border-bottom: 2px solid #ddd;
        }
        #results-list span.tag {
            display: inline-block;
            padding: 3px 4px;
            margin-right: 8px;
            position: relative;
            top: -2px;

            background: #888;
            color: #fff;

            font-size: 0.75em;
            font-weight: 600;
            line-height: 1;
            text-transform: uppercase;

            -webkit-border-radius: 2px;
            -moz-border-radius: 2px;
            border-radius: 2px;
        }
    </style></head>
    <body role="document">
        <!--[if lt IE 7]>
            <p class="chromeframe">You are using an <strong>outdated</strong> browser. Please <a href="http://browsehappy.com/">upgrade your browser</a> or <a href="http://www.google.com/chromeframe/?redirect=true">activate Google Chrome Frame</a> to improve your experience.</p>
        <![endif]-->

      <div id="container"><header role="banner">
        <div>
          <h1><a href="../pages/home.html">NeuPy</a></h1>
          <h2>Neural Networks in Python</h2>
        </div>
    </header>
    <nav role="navigation">
      <ul>
        <li class="main-nav">
          <a href="../archive.html">Articles</a>
        </li>
        <li class="main-nav">
          <a href="tutorials.html">Tutorials</a>
        </li>
        <li class="main-nav">
          <a href="../pages/documentation.html">Documentation</a>
        </li>
        <li class="main-nav">
          <a href="../pages/cheatsheet.html">Cheat sheet</a>
        </li>
        <li class="main-nav">
          <a href="../pages/model_zoo.html">Model Zoo</a>
        </li>
      </ul>
    </nav>

<div class="main-container" role="main"><div class="main wrapper body clearfix"><article>
    <div class="section" id="transfer-learning">
<h1>Transfer Learning</h1>
<p>Transfer learning allows us to transfer knowledge learned from one network to different network that aims to solve similar problem. There are two main advantages for this. First, we don’t need to start learning from scratch using some random parameters and since we don’t start from scratch training should be faster. Second, training on the small datasets might be problematic and prune to overfitting, but with pre-trained layers we can transfer knowledge that has been extracted from large dataset.</p>
<p>In this part of the documentation, we can see how transfer learning can be used in NeuPy. As an example, we can build classifier that expects bird image as an input and it classifies it as one of the 10 bird species. For this task, we can use VGG16 network which was pre-trained using ImageNet data. First, we can use architecture that has been already defined in NeuPy library.</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">neupy</span> <span class="kn">import</span> <span class="n">architectures</span><span class="p">,</span> <span class="n">layers</span>
<span class="c1"># At this point vgg16 has only random parameters</span>
<span class="n">vgg16</span> <span class="o">=</span> <span class="n">architectures</span><span class="o">.</span><span class="n">vgg16</span><span class="p">()</span>
</pre></div>
</div>
<p>When we load it by default it has randomly generated parameters. We can load pre-trained parameters using <span class="docutils literal"><span class="pre">neupy.storage</span></span> module. You can download pre-trained models from <a class="reference internal" href="../pages/model_zoo.html#model-zoo"><span class="std std-ref">Model Zoo</span></a>.</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">neupy</span> <span class="kn">import</span> <span class="n">storage</span>
<span class="n">storage</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">vgg16</span><span class="p">,</span> <span class="s1">&#39;/path/to/vgg16.hdf5&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>We can check what input and output shapes network expects.</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">vgg16</span><span class="o">.</span><span class="n">input_shape</span>
<span class="go">(3, 224, 224)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">vgg16</span><span class="o">.</span><span class="n">output_shape</span>
<span class="go">(1000,)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">vgg16</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="o">-</span><span class="mi">3</span><span class="p">:]</span>  <span class="c1"># check last 3 layers</span>
<span class="go">[Relu(4096), Dropout(proba=0.5), Softmax(1000)]</span>
</pre></div>
</div>
<p>Another way to visualise structure of the network is to use <span class="docutils literal"><span class="pre">neupy.plots</span></span> api.</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">neupy</span> <span class="kn">import</span> <span class="n">plots</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">plots</span><span class="o">.</span><span class="n">network_structure</span><span class="p">(</span><span class="n">vgg16</span><span class="p">)</span>
</pre></div>
</div>
<p>In both cases, we can see that final layer layer makes prediction for 1,000 classes, but for our problem we need only 10. In NeuPy, you can easily slice over the network in order to cut layers that 23 don’t need. If you visualized network using the <span class="docutils literal"><span class="pre">plots.network_structure</span></span> function than you should have noticed that it has dropout layer before the final layer. We can use it as a reference point for slicing.</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">dropout</span> <span class="o">=</span> <span class="n">vgg16</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">vgg16</span><span class="o">.</span><span class="n">end</span><span class="p">(</span><span class="n">dropout</span><span class="p">)</span>
<span class="go">(3, 224, 224) -&gt; [... 37 layers ...] -&gt; 4096</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">vgg16_modified</span> <span class="o">=</span> <span class="n">vgg16</span><span class="o">.</span><span class="n">end</span><span class="p">(</span><span class="n">dropout</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">layers</span><span class="o">.</span><span class="n">Softmax</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">vgg16_modified</span>
<span class="go">(3, 224, 224) -&gt; [... 38 layers ...] -&gt; 10</span>
</pre></div>
</div>
<p>The <span class="docutils literal"><span class="pre">vgg16_modified</span></span> network has new architecture that re-uses all layers except the last one from VGG16 architecture and combines it with new <span class="docutils literal"><span class="pre">Softmax(10)</span></span> layer that we added specificily for out bird classifier.</p>
<p>In order to speed up transfer learning, we can exclude transferred layers from the training. They already has been pre-trained for us and in some applications we can just use them without modification. It can give us significant speed up in training time. For this problem we have to explicitly separate our architecture into two different parts. First one should have pre-trained layers and the other one new layers with randomly generated weights.</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">pretrained_vgg16_part</span> <span class="o">=</span> <span class="n">vgg16</span><span class="o">.</span><span class="n">end</span><span class="p">(</span><span class="n">dropout</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">pretrained_vgg16_part</span>
<span class="go">(3, 224, 224) -&gt; [... 37 layers ...] -&gt; 4096</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">pretrained_vgg16_part</span><span class="o">.</span><span class="n">output_shape</span>
<span class="go">(4096,)</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">new_vgg16_part</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="mi">4096</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">layers</span><span class="o">.</span><span class="n">Softmax</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
<span class="go">Input(4096) &gt; Softmax(10)</span>
</pre></div>
</div>
<p>You can notice that for the last layer we create small network adding <span class="docutils literal"><span class="pre">Input(4096)</span></span> layer. In this way we’re saying that network expects input with 4096 features. It’s exactly the same number of feature that we get if we propagate image through pre-trained part of the VGG16. We can transform our input images into vectors with 4096 features after propagating through the pre-trained VGG16 layers. We do it in order to speed up training for the last layer and avoid training for the pre-trained layers. We will use embedded features (4096-dimensional) that we get per each image and our training data for the new layers that we added for our bird classifier.</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">neupy</span> <span class="kn">import</span> <span class="n">algorithms</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Loading 10,000 image that would be pre-processed in the</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># same way as it was done during training on ImageNet data.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Labels were encoded with one hot encoder.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">images</span><span class="p">,</span> <span class="n">targets</span> <span class="o">=</span> <span class="n">load_prepared_image_and_labels</span><span class="p">()</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">embedded_images</span> <span class="o">=</span> <span class="n">pretrained_vgg16_part</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">images</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">embedded_images</span><span class="o">.</span><span class="n">shape</span>
<span class="go">(10000, 4096)</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">momentum</span> <span class="o">=</span> <span class="n">algorithms</span><span class="o">.</span><span class="n">Momentum</span><span class="p">(</span><span class="n">new_vgg16_part</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">momentum</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">embedded_images</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
</pre></div>
</div>
<p>When we finished training, the last layer in the network can be combined with pre-trained VGG16 layers and create full network that we will use to classify birds from images.</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">pretrained_vgg16_part</span> <span class="o">&gt;</span> <span class="n">new_vgg16_part</span>
<span class="go">(3, 224, 224) -&gt; [... 39 layers ...] -&gt; 10</span>
</pre></div>
</div>
<p>Notice, that we still have our <span class="docutils literal"><span class="pre">Input(4096)</span></span> in the <span class="docutils literal"><span class="pre">new_vgg16_part</span></span> network. To make our final architecture cleaner we can simply use only last layer from the <span class="docutils literal"><span class="pre">new_vgg16_part</span></span> network or just use network without first input layer.</p>
<p>If you have enough computational resources and/or you’re not satisfied with the accuracy that you get than you can try to remove more layers from the pre-trained network. Also, you can use network that you combined from pre-trained parts and newly trained layer (or multiple layers) and fine-tune layers using the same images, but this time you should use all layers from the network during the training.</p>
</div>

    <div class="postmeta">
        
        
        
        </div><ul class="related clearfix">
            <li class="left"> &laquo; <a href="algorithms/sklearn-compatibility.html">Scikit-learn compatibility</a></li>
            <li class="right"><a href="storage.html">Storage for Neural Networks</a> &raquo; </li>
        </ul></article><aside class="sidebar"><section><div class="widget" id="searchbox" role="search">
    <h1><a href="#searchbox">Search</a></h1>
    <form action="../search.html" method="get">
          <div class="box">
            <div class="search-input-container">
                <span class="icon"><i class="fa fa-search"></i></span>
                <input type="search" name="q" id="search" placeholder="Search..." />
            </div>
          </div>
    </form>
</div></section><section><div class="widget">
    <h1>Install NeuPy</h1>
    <div class="highligh-bash">
        <div class="highlight">
            <pre>pip install neupy</pre>
        </div>
    </div>
    <p>
        <div>Learn more about NeuPy reading <a href="tutorials.html">tutorials</a> and <a href="../pages/documentation.html">documentation</a>.</div>
    </p>
</div></section><section><div class="widget">
    <h1>Issues and feature requests</h1>
    <p>
        If you find a bug or want to suggest a new feature feel free to
        <a href="https://github.com/itdxer/neupy/issues/new">create an issue</a>
        on Github
    </p>
</div></section></aside></div> <!-- #main --></div> <!-- #main-container -->

        <div class="footer-container" role="contentinfo"><footer class="wrapper">&copy; Copyright 2015 - 2019, Yurii Shevchuk. Powered by <a href="http://www.tinkerer.me/">Tinkerer</a> and <a href="http://sphinx.pocoo.org/">Sphinx</a>.</footer></div> <!-- footer-container -->

      </div> <!--! end of #container --><script type="text/javascript">    var disqus_shortname = "neupy";    disqus_count();</script><!--[if lt IE 7 ]>
          <script src="//ajax.googleapis.com/ajax/libs/chrome-frame/1.0.3/CFInstall.min.js"></script>
          <script>window.attachEvent('onload',function(){CFInstall.check({mode:'overlay'})})</script>
        <![endif]-->
    </body>
</html>